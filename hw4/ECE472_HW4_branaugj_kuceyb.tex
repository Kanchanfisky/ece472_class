\documentclass[letterpaper,10pt,titlepage]{article}

\usepackage{graphicx}                                        
\usepackage{amssymb}                                         
\usepackage{amsmath}                                         
\usepackage{amsthm}                                          

\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage{url}

%\usepackage{balance}
%\usepackage[TABBOTCAP, tight]{subfigure}
%\usepackage{enumitem}
\usepackage{pstricks, pst-node}

\usepackage{geometry}
\geometry{textheight=9in, textwidth=6.5in}

%random comment

\newcommand{\cred}[1]{{\color{red}#1}}
\newcommand{\cblue}[1]{{\color{blue}#1}}

\usepackage{hyperref}
\usepackage{geometry}

\def\name{Jacob Branaugh, Brenn Kucey}

%% The following metadata will show up in the PDF properties
\hypersetup{
  colorlinks = true,
  urlcolor = black,
  pdfauthor = {\name},
  pdfkeywords = {cs472 ``computer architecture'' clements ``chapter 4''},
  pdftitle = {CS 472: Homework 4},
  pdfsubject = {CS 472: Homework 4},
  pdfpagemode = UseNone
}

\begin{document}
\hfill \name

\hfill \today

\hfill CS 472 HW 4

\begin{enumerate}
	\item[(9.2)] Why do computers use cache memory?
	\item[\textbullet] Computers use cache memory because it transfers data quickly,
		and has a much larger capacity than the processor's registers. Cache
		memory is slightly slower than registers, but is significantly faster than
		RAM. There are only a handful of registers available, whereas cache can
		range from kB to MB. RAM, however, is usually available in the order of
		GB.

	\item[(9.3)] What is the meaning of the following terms?
	\item[\textbullet] Temporal locality
	\item[-] Temporal locality describes the number of times a memory address is
		accessed within some amount of time.
	\item[\textbullet] Spatial locality
	\item[-] Spatial locality is a term to describe the physical closeness of related
		memory addresses.

	\item[(9.4)] From first principles, derive an expression for the speedup ratio of
		a memory system with cache (assume the hit ratio is h and the ratio of the
		main storage access time to cache access time is k, where k \textless\ 1). 
		Assume that the system is an ideal system and that you don't have to worry 
		about the effect of clock cycle times.
	\item[\textbullet] $S=\frac{1}{1-h(1-k)}\ ,\ k = \frac{t_{c}}{t_{m}}$

	\item[(9.5)] For the following ideal systems, calculate the speedup ratio S. In
		each case, $t_{c}$ is the access time of the cache memory, $t_{m}$ is the
		access time of the main store, and h is the hit ratio.
	\item[a)] $t_{m} = 70ns, t_{c} = 7ns, h = .9$ \\ \\
		$S=\frac{1}{1-.9(1-\frac{7}{70})}=$ \textbf{5.263}
	\item[b)] $t_{m} = 60ns, t_{c} = 3ns, h = .9$ \\ \\
		$S=\frac{1}{1-.9(1-\frac{3}{60})}=$ \textbf{6.897}
	\item[c)] $t_{m} = 60ns, t_{c} = 3ns, h = .8$ \\ \\
		$S=\frac{1}{1-.8(1-\frac{3}{60})}=$ \textbf{4.167}
	\item[d)] $t_{m} = 60ns, t_{c} = 3ns, h = .97$ \\ \\
		$S=\frac{1}{1-.97(1-\frac{3}{60})}=$ \textbf{12.739}

	\item[(9.6)] For the following ideal systems, calculate the hit ratio h required to
		achieve the stated speedup ratio S.
	\item[a)] $t_{m} = 60ns, t_{c} = 3ns, S = 1.1$ \\ \\
		$h=\frac{1-\frac{1}{S}}{1-\frac{t_{c}}{t_{m}}}=\frac{1-\frac{1}{1.1}}{1-\frac{3}{30}}=$
		\textbf{0.096}
	\item[b)] $t_{m} = 60ns, t_{c} = 3ns, S = 2.0$ \\ \\
		$h=\frac{1-\frac{1}{2}}{1-\frac{3}{60}}=$ \textbf{0.526}
	\item[c)] $t_{m} = 60ns, t_{c} = 3ns, S = 5.0$ \\ \\
		$h=\frac{1-\frac{1}{5}}{1-\frac{3}{60}}=$ \textbf{0.842}
	\item[d)] $t_{m} = 60ns, t_{c} = 3ns, S = 15.0$ \\ \\
		$h=\frac{1-\frac{1}{15}}{1-\frac{3}{60}}=$ \textbf{0.982}

	\item[(9.8)] For the following systems that use a clocked microprocessor,
		calculate the maximum speedup ratio you could expect to see as h approaches
		100\%.\\ \\
		$S=\frac{1}{1-1(1-\frac{t_{c}}{t_{m}})}=\frac{1}{\frac{t_{c}}{t_{m}}}=\frac{t_{m}}{t_{c}}$
		, where $t_{m}\ and\ t_{c}$ must be integer multiples of the time taken for
		one clock cycle.
	\item[a)] $t_{cyc} = 20ns, t_{m} = 75ns, t_{c} = 15ns$ \\ \\
		$t_{m}=75ns \rightarrow t_{m}=4\ cycles$ \\
		$t_{c}=15ns \rightarrow t_{c}=1\ cycle$ \\
		$S=\frac{4}{1}=$ \textbf{4}

	\item[b)] $t_{cyc} = 20ns, t_{m} = 75ns, t_{c} = 25ns$ \\ \\
		$t_{m}=75ns \rightarrow t_{m}=4\ cycles$ \\
		$t_{c}=25ns \rightarrow t_{c}=2\ cycle$ \\
		$S=\frac{4}{2}=$ \textbf{2}

	\item[c)] $t_{cyc} = 10ns, t_{m} = 75ns, t_{c} = 15ns$ \\ \\
		$t_{m}=75ns \rightarrow t_{m}=8\ cycles$ \\
		$t_{c}=15ns \rightarrow t_{c}=2\ cycle$ \\
		$S=\frac{8}{2}=$ \textbf{4}

	\item[(9.11)] In a direct-mapped cache memory system, what is the meaning of the
		following terms.
	\item[\textbullet] Word: the number of bytes a processor core can process during
		one clock cycle, usually no larger than 64 bits
	\item[\textbullet] Line: the minimum amount of data transferable between cache
		and main memory at a time, equal to a small number of words
	\item[\textbullet] Set: a collection of lines equal to $\frac{size\ of\ main\
		memory}{size\ of\ cache}$

	\item[(9.12)] How is data in main store mapped on to each of the following?
	\item[\textbullet] Direct mapped cache: main memory is organized into sets, which
		are organized into lines (see 9.11)
	\item[\textbullet] Fully associative cache: cache takes a line directly from main
		memory and each line is paired with a tag address location and a bit that
		stores the state of the data's validity. This is an expensive type of
		cache, as it requires physical space for both the data bits and the tag
		bits, resulting in either twice the cache size needed or half the cache
		size usable.
	\item[\textbullet] Set associative cache: the cache contains multiple sets, where
		the address of any given line is the same across all sets. The sets are
		searched in parallel, and a match in any set causes the search to end.

	\item[(9.17)] What is cache coherency?
	\item[\textbullet] Cache coherency is the state of a piece of data in cache versus
		the state of that same piece of data in main memory. Since data living in
		the cache also exists in the main store, both copies must be updated when
		the processor modifies the data. If the data in one is updated but data in
		the other has not yet been updated, the old data may be grabbed and used
		further.

	\item[(9.22)] Why is it harder to design a data cache than an instruction cache?
	\item[\textbullet] Because an entry in the instruction cache is never modified
		outside of the initial swapping in. Additionally, the instructions that
		are overwritten in the I-cache don't matter anymore, as the program
		doesn't change during its execution.

	\item[(9.23)] When a CPU writes to cache, both the item in the cache and the
		corresponding item in the memory must be updated. If data is not in the
		cache, it must be fetched from memory and loaded in the cache. If $t_{1}$
		is the time taken to reload the cache on a miss, show that the effective
		average access time of the memory system is given by \\ \\
		$t_{avg}=ht_{c}+(1-h)t_{m}+(1-h)t_{1}$
	\item[\textbullet] The average access time assuming no cache reload is:\\
		$t_{avg}=ht_{c}+(1-h)t_{m}$,\\
		meaning the cache access time multiplied by the hit percentage plus the
		memory access time multiplied by the cache-miss percentage.
	\item[\textbullet] Now, assuming the cache takes time to reload after miss, that
		time must simply be added to our existing access time, giving:\\
		$t_{avg}=ht_{c}+(1-h)t_{m}+(1-h)t_{1}$,\\
		where our access time is the cache-hit percentage multiplied by the time
		taken for cache hit plus cache-miss percentage multiplied by the time
		taken for memory access plus cache-miss percentage multiplied by the time
		taken to reload the cache on miss.

	\item[(9.26)] A system has a level 1 cache and a level 2 cache. The hit rate of
		the level 1 cache is 90\%, and the hit rate of the level 2 cache is 80\%.
		An access to level 1 cache requires one cycle, an access to level 2 cache
		requires four cycles, and an access to main store requires 50 cycles. What
		is the average access time?
	\item[\textbullet]
		$t_{avg}=h_{1}t_{c1}+(1-h_{1})h_{2}t_{c2}+(1-h_{1})(1-h_{2})t_{m}=.9\times1+.1\times.8\times4+.1\times.2\times50=$ \textbf{2.22 cycles}

	\item[(9.28)] In the context of of multilevel caches, what is the difference
		between a local miss rate and a global miss rate?
	\item[\textbullet] A local miss rate is the miss rate of a given cache independent
		of the miss rates of the rest. The global miss rate is the miss rate of
		all present caches, or the complement of the total memory access rate.

	\item[(9.35)] A 64-bit processor has an 8-MB, four-way set-associative cache with
		32-byte lines. How is the address arranged in terms of set, line, and
		offset bits?
	\item[\textbullet] 

	\item[(9.41)] What are the fundamental differences between cache memory as found
		in a CPU and cache memory as found in a hard disk drive?
	\item[\textbullet] CPU cache holds lines, hard disk cache holds pages.

	\item[(9.42)] What are the differences between write-back and write-through
		caches, and what are the implications for system performance?
	\item[\textbullet] Write-through caching is when the main memory is updated at the
		same time as the cache is loaded. This is the lower performance method, as
		the write time to memory is much slower than write time to cache.
	\item[\textbullet] Write-back caching is when main memory is updated only when the
		cache is going to eject a line, which will be written back to main memory.
		This is the higher performance method, as fewer slow memory operations
		will be taking place.

	\item[(9.43)] A computer with a 32-bit address architecture has a memory
		management system with single-level 4KB page tables. How much memory space
		must be devoted to the page tables?

	\item[(9.45)] A computer runs an instruction set with the characteristics in the
		following table:\\ \\
		\begin{tabular}{ l l l }
			Class & Instruction Frequency & Cycles \\
			\hline
			Arithmetic Operations & 70\% & 1 \\
			Conditional Operations & 15\% & 2 \\
			Load & 10\% & 2 \\
			Store & 5\% & 2 \\
			Hit Rate & 95\% & \\
			Cost of Cache Miss (Read) & & 10 \\
			Write-Through Time & & 5 \\
			(Writes to Memory Are Not Buffered) & & \\ 
		\end{tabular} \\ \\
		What is the average number of cycles per instruction?
	\item[\textbullet] Do math here

	\item[(9.46)] Consider the following code that accesses three values in memory
		scalar integers x and s, and an integer vector y[i]. What is the memory
		latency in clock cycles for a trip round the loop (after the first
		iteration)? Assume that the array is not cached and each new access to the
		array results in a miss. The system has both L1 and L2 caches. The access
		time of the L1 cache is two cycles, the access time of the L2 cache is 6
		cycles, and main memory has an access time of 50 cycles. In this case all
		memory and cache memory access take place in parallel.
		\begin{verbatim}
		for (i = 0; i < 100; i++) {
		        x = y[i];
		        s = s + x;
		}
		\end{verbatim}
	\item[\textbullet] More math possibly?

	\item[(9.57)] A computer with a 24-bit address bus has a main memory size of 16 MB
		and a cache size of 64KB. The wordlength is two bytes.
	\item[a)] What is the address format for a direct-mapped cache with a line size of
		32 words?
	\item[\textbullet] asdf
	\item[b)] What is the address format for a fully associative cache with a line
		size of 32 words?
	\item[\textbullet] asdf
	\item[c)] What is the address format for a four-way set-associative cache with a
		line size of 16 words?
	\item[\textbullet] asdf


\end{enumerate}

\end{document}
